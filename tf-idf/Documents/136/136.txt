you are given a 0-indexed integer array nums of length n.
the average difference of the index i is the absolute difference between the average of the first i + 1 elements of nums and the average of the last n - i - 1 elements. both averages should be rounded down to the nearest integer.
return the index with the minimum average difference. if there are multiple such indices, return the smallest one.
note:
the absolute difference of two numbers is the absolute value of their difference.
the average of n elements is the sum of the n elements divided (integer division) by n.
the average of 0 elements is considered to be 0.
